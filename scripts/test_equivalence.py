#!/usr/bin/env python3
"""
EQUIVALENCE TEST: Live Bot vs TPE Validate

This script answers the critical question:
"Would main_live_bot.py generate the EXACT same signals as TPE validate?"

We simulate the live bot's scan_symbol() logic on historical data and compare
the signals against the TPE validate trade results.

METHODOLOGY:
1. Load TPE validate trades from CSV
2. For each date in 2023-2025, simulate what live bot would see
3. Run identical signal generation logic  
4. Compare signals day-by-day
5. Report discrepancies

Author: AI Assistant
Date: January 5, 2026
"""

import sys
import os
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Set, Tuple, Any
from dataclasses import dataclass
import pandas as pd
import json

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

from strategy_core import (
    compute_confluence,
    _infer_trend,
    _pick_direction_from_bias,
    _slice_htf_by_timestamp,
    StrategyParams,
    apply_volatile_asset_boost,
)
from params.params_loader import load_strategy_params

# Constants
WORKSPACE = Path(__file__).resolve().parent.parent
TPE_TRADES_PATH = WORKSPACE / "ftmo_analysis_output" / "VALIDATE" / "best_trades_final.csv"
DATA_DIR = WORKSPACE / "data" / "ohlcv"


@dataclass
class SignalKey:
    """Unique identifier for a signal"""
    date: str  # YYYY-MM-DD
    symbol: str
    direction: str
    
    def __hash__(self):
        return hash((self.date, self.symbol, self.direction))
    
    def __eq__(self, other):
        return (self.date, self.symbol, self.direction) == (other.date, other.symbol, other.direction)


@dataclass 
class SimulatedSignal:
    """Signal generated by simulated live bot"""
    date: str
    symbol: str
    direction: str
    entry_price: float
    stop_loss: float
    confluence_score: int
    quality_factors: int
    flags: Dict[str, bool]


def oanda_to_mt5_symbol(oanda_symbol: str) -> str:
    """Convert OANDA format (EUR_USD) to MT5 format (EURUSD)."""
    # Special mappings
    special = {
        "XAU_USD": "XAUUSD",
        "XAG_USD": "XAGUSD",
        "BTC_USD": "BTCUSD",
        "ETH_USD": "ETHUSD",
        "NAS100_USD": "NAS100USD",
        "SPX500_USD": "SPX500USD",
    }
    if oanda_symbol in special:
        return special[oanda_symbol]
    # Standard: remove underscore
    return oanda_symbol.replace("_", "")


def load_ohlcv_data(symbol: str, timeframe: str = "D") -> List[Dict]:
    """Load OHLCV data for a symbol and timeframe."""
    # Convert OANDA symbol to MT5 format for file lookup
    mt5_symbol = oanda_to_mt5_symbol(symbol)
    
    # Map timeframe to filename pattern (D -> D1, W -> W1, M -> MN, H4 -> H4)
    tf_map = {
        "M": "MN",
        "W": "W1", 
        "D": "D1",
        "H4": "H4",
        "H1": "H1",
    }
    
    ohlcv_dir = DATA_DIR
    tf_code = tf_map.get(timeframe, timeframe)
    pattern = f"{mt5_symbol}_{tf_code}_2003_2025.csv"
    filepath = ohlcv_dir / pattern
    
    if not filepath.exists():
        return []
    
    try:
        df = pd.read_csv(filepath)
        
        # Normalize column names
        df.columns = df.columns.str.lower()
        
        # Rename 'datetime' to 'time' if needed
        if 'datetime' in df.columns and 'time' not in df.columns:
            df.rename(columns={'datetime': 'time'}, inplace=True)
        
        # Convert to list of dicts
        candles = df.to_dict('records')
        
        # Ensure time is datetime
        for c in candles:
            if 'time' in c:
                if isinstance(c['time'], str):
                    try:
                        c['time'] = pd.to_datetime(c['time'])
                    except:
                        pass
        
        return candles
    except Exception as e:
        print(f"Error loading {filepath}: {e}")
        return []


def get_candles_up_to_date(candles: List[Dict], target_date: datetime) -> List[Dict]:
    """
    Get all candles up to and including target_date.
    This simulates what the live bot would see on that date.
    NO LOOK-AHEAD BIAS - only past data.
    """
    result = []
    for c in candles:
        candle_time = c.get('time')
        if candle_time is None:
            continue
            
        if isinstance(candle_time, str):
            try:
                candle_time = pd.to_datetime(candle_time)
            except:
                continue
        
        # Remove timezone info for comparison
        if hasattr(candle_time, 'tzinfo') and candle_time.tzinfo:
            candle_time = candle_time.replace(tzinfo=None)
            
        target_naive = target_date.replace(tzinfo=None) if hasattr(target_date, 'tzinfo') and target_date.tzinfo else target_date
        
        if candle_time.date() <= target_naive.date():
            result.append(c)
    
    return result


def simulate_live_bot_signal(
    symbol: str,
    date: datetime,
    daily_candles: List[Dict],
    weekly_candles: List[Dict],
    monthly_candles: List[Dict],
    h4_candles: List[Dict],
    params: StrategyParams,
) -> Optional[SimulatedSignal]:
    """
    Simulate EXACTLY what main_live_bot.py scan_symbol() would do on this date.
    
    This mirrors the logic in main_live_bot.py lines 1063-1250.
    """
    # Slice data up to this date (NO FUTURE DATA)
    daily_slice = get_candles_up_to_date(daily_candles, date)
    weekly_slice = get_candles_up_to_date(weekly_candles, date)
    monthly_slice = get_candles_up_to_date(monthly_candles, date)
    h4_slice = get_candles_up_to_date(h4_candles, date)
    
    # Minimum data requirements (same as live bot)
    if len(daily_slice) < 50:
        return None
    if len(weekly_slice) < 10:
        return None
    
    # HTF trend analysis (same as live bot)
    mn_trend = _infer_trend(monthly_slice) if monthly_slice else "mixed"
    wk_trend = _infer_trend(weekly_slice) if weekly_slice else "mixed"
    d_trend = _infer_trend(daily_slice) if daily_slice else "mixed"
    
    # Direction from bias (same as live bot)
    direction, _, _ = _pick_direction_from_bias(mn_trend, wk_trend, d_trend)
    
    # Compute confluence (same as live bot)
    # Note: live bot passes historical_sr=None for most cases
    flags, notes, trade_levels = compute_confluence(
        monthly_slice,
        weekly_slice,
        daily_slice,
        h4_slice if h4_slice else daily_slice[-20:],
        direction,
        params,
        historical_sr=None,
    )
    
    entry, sl, tp1, tp2, tp3, tp4, tp5 = trade_levels
    
    confluence_score = sum(1 for v in flags.values() if v)
    
    # Quality factors (EXACT same as main_live_bot.py)
    has_location = flags.get("location", False)
    has_fib = flags.get("fib", False)
    has_liquidity = flags.get("liquidity", False)
    has_structure = flags.get("structure", False)
    has_htf_bias = flags.get("htf_bias", False)
    quality_factors = sum([has_location, has_fib, has_liquidity, has_structure, has_htf_bias])
    
    # Status check (EXACT same as main_live_bot.py)
    # MIN_CONFLUENCE comes from ftmo_config
    MIN_CONFLUENCE = params.min_confluence
    MIN_QUALITY = params.min_quality_factors
    
    if confluence_score >= MIN_CONFLUENCE and quality_factors >= MIN_QUALITY:
        status = "active"
    elif confluence_score >= MIN_CONFLUENCE:
        status = "watching"
    else:
        status = "scan_only"
    
    if status != "active":
        return None
    
    if entry is None or sl is None:
        return None
    
    return SimulatedSignal(
        date=date.strftime("%Y-%m-%d"),
        symbol=symbol,
        direction=direction,
        entry_price=entry,
        stop_loss=sl,
        confluence_score=confluence_score,
        quality_factors=quality_factors,
        flags=flags,
    )


def load_tpe_trades() -> pd.DataFrame:
    """Load TPE validate trades from CSV."""
    if not TPE_TRADES_PATH.exists():
        print(f"ERROR: TPE trades file not found: {TPE_TRADES_PATH}")
        sys.exit(1)
    
    df = pd.read_csv(TPE_TRADES_PATH)
    print(f"Loaded {len(df)} TPE validate trades")
    return df


def get_available_symbols() -> List[str]:
    """Get list of symbols with available data (returns OANDA format)."""
    symbols = set()
    for f in DATA_DIR.glob("*_D1_2003_2025.csv"):
        # Extract MT5 symbol from filename (e.g., EURUSD_D1_2003_2025.csv -> EURUSD)
        name = f.stem
        mt5_symbol = name.split("_D1_")[0]
        # Convert MT5 format to OANDA format for consistency
        oanda_symbol = mt5_to_oanda_symbol(mt5_symbol)
        symbols.add(oanda_symbol)
    return sorted(symbols)


def mt5_to_oanda_symbol(mt5_symbol: str) -> str:
    """Convert MT5 format (EURUSD) to OANDA format (EUR_USD)."""
    # Special mappings
    special = {
        "XAUUSD": "XAU_USD",
        "XAGUSD": "XAG_USD",
        "BTCUSD": "BTC_USD",
        "ETHUSD": "ETH_USD",
        "NAS100USD": "NAS100_USD",
        "SPX500USD": "SPX500_USD",
    }
    if mt5_symbol in special:
        return special[mt5_symbol]
    # Standard FX pairs - insert underscore before last 3 chars
    if len(mt5_symbol) == 6:
        return mt5_symbol[:3] + "_" + mt5_symbol[3:]
    return mt5_symbol


def run_equivalence_test(
    start_date: str = "2023-01-01",
    end_date: str = "2025-12-31",
    verbose: bool = False,
) -> Dict[str, Any]:
    """
    Run the full equivalence test.
    
    Returns detailed comparison results.
    """
    print("=" * 70)
    print("EQUIVALENCE TEST: Live Bot vs TPE Validate")
    print("=" * 70)
    print(f"\nPeriod: {start_date} to {end_date}")
    
    # Load parameters
    params = load_strategy_params()
    print(f"\nParameters loaded:")
    print(f"  - min_confluence: {params.min_confluence}")
    print(f"  - min_quality_factors: {params.min_quality_factors}")
    
    # Load TPE trades
    tpe_df = load_tpe_trades()
    
    # Parse dates
    tpe_df['entry_date_parsed'] = pd.to_datetime(tpe_df['entry_date'])
    tpe_df['date_only'] = tpe_df['entry_date_parsed'].dt.strftime('%Y-%m-%d')
    
    # Get available symbols
    available_symbols = get_available_symbols()
    print(f"\nAvailable symbols in data: {len(available_symbols)}")
    
    # Get unique symbols from TPE trades
    tpe_symbols = tpe_df['symbol'].unique().tolist()
    print(f"Symbols in TPE trades: {len(tpe_symbols)}")
    
    # Find common symbols
    common_symbols = [s for s in tpe_symbols if s in available_symbols]
    print(f"Common symbols (testable): {len(common_symbols)}")
    
    if not common_symbols:
        print("\nERROR: No common symbols found!")
        return {"error": "No common symbols"}
    
    # Build TPE signal set
    print("\n" + "-" * 70)
    print("Building TPE signal set...")
    tpe_signals: Set[SignalKey] = set()
    tpe_signal_details: Dict[SignalKey, Dict] = {}
    
    for _, row in tpe_df.iterrows():
        key = SignalKey(
            date=row['date_only'],
            symbol=row['symbol'],
            direction=row['direction'],
        )
        tpe_signals.add(key)
        tpe_signal_details[key] = {
            'entry_price': row['entry_price'],
            'stop_loss': row['stop_loss'],
            'confluence_score': row.get('confluence_score', 0),
            'quality_factors': row.get('quality_factors', 0),
        }
    
    print(f"TPE signals: {len(tpe_signals)}")
    
    # Simulate live bot for each date and symbol
    print("\n" + "-" * 70)
    print("Simulating live bot on historical data...")
    print("(This may take a few minutes)\n")
    
    # Pre-load all data
    all_data: Dict[str, Dict[str, List[Dict]]] = {}
    for symbol in common_symbols:
        all_data[symbol] = {
            'D': load_ohlcv_data(symbol, 'D'),
            'W': load_ohlcv_data(symbol, 'W'),
            'M': load_ohlcv_data(symbol, 'M'),
            'H4': load_ohlcv_data(symbol, 'H4'),
        }
        if verbose:
            print(f"  Loaded {symbol}: D={len(all_data[symbol]['D'])}, W={len(all_data[symbol]['W'])}, M={len(all_data[symbol]['M'])}")
    
    # Generate date range
    date_range = pd.date_range(start=start_date, end=end_date, freq='D')
    total_days = len(date_range)
    
    live_signals: Set[SignalKey] = set()
    live_signal_details: Dict[SignalKey, SimulatedSignal] = {}
    
    processed = 0
    for current_date in date_range:
        # Skip weekends
        if current_date.weekday() >= 5:
            continue
        
        for symbol in common_symbols:
            data = all_data[symbol]
            
            signal = simulate_live_bot_signal(
                symbol=symbol,
                date=current_date.to_pydatetime(),
                daily_candles=data['D'],
                weekly_candles=data['W'],
                monthly_candles=data['M'],
                h4_candles=data['H4'],
                params=params,
            )
            
            if signal:
                key = SignalKey(
                    date=signal.date,
                    symbol=signal.symbol,
                    direction=signal.direction,
                )
                live_signals.add(key)
                live_signal_details[key] = signal
        
        processed += 1
        if processed % 100 == 0:
            print(f"  Processed {processed}/{total_days} days... ({len(live_signals)} signals so far)")
    
    print(f"\nLive bot signals: {len(live_signals)}")
    
    # Compare
    print("\n" + "=" * 70)
    print("COMPARISON RESULTS")
    print("=" * 70)
    
    only_in_tpe = tpe_signals - live_signals
    only_in_live = live_signals - tpe_signals
    in_both = tpe_signals & live_signals
    
    match_rate = len(in_both) / len(tpe_signals) * 100 if tpe_signals else 0
    
    print(f"\n‚úÖ Signals in BOTH:        {len(in_both):>6}")
    print(f"‚ùå Only in TPE validate:   {len(only_in_tpe):>6}")
    print(f"‚ùå Only in Live Bot sim:   {len(only_in_live):>6}")
    print(f"\nüìä Match Rate:             {match_rate:.1f}%")
    
    # Analyze discrepancies
    if only_in_tpe:
        print(f"\n‚ö†Ô∏è  SIGNALS ONLY IN TPE VALIDATE (first 10):")
        for key in list(only_in_tpe)[:10]:
            details = tpe_signal_details.get(key, {})
            print(f"   {key.date} | {key.symbol:12} | {key.direction:7} | Conf: {details.get('confluence_score', '?')}")
    
    if only_in_live:
        print(f"\n‚ö†Ô∏è  SIGNALS ONLY IN LIVE BOT (first 10):")
        for key in list(only_in_live)[:10]:
            signal = live_signal_details.get(key)
            if signal:
                print(f"   {key.date} | {key.symbol:12} | {key.direction:7} | Conf: {signal.confluence_score}")
    
    # Detailed comparison for matched signals
    if in_both:
        print(f"\nüîç DETAILED COMPARISON (first 5 matched):")
        for key in list(in_both)[:5]:
            tpe_detail = tpe_signal_details.get(key, {})
            live_signal = live_signal_details.get(key)
            
            if live_signal and tpe_detail:
                entry_diff = abs(tpe_detail['entry_price'] - live_signal.entry_price)
                sl_diff = abs(tpe_detail['stop_loss'] - live_signal.stop_loss)
                
                print(f"\n   {key.date} {key.symbol} {key.direction}:")
                print(f"     Entry:  TPE={tpe_detail['entry_price']:.5f}, Live={live_signal.entry_price:.5f}, Diff={entry_diff:.5f}")
                print(f"     SL:     TPE={tpe_detail['stop_loss']:.5f}, Live={live_signal.stop_loss:.5f}, Diff={sl_diff:.5f}")
                print(f"     Conf:   TPE={tpe_detail['confluence_score']}, Live={live_signal.confluence_score}")
    
    # Summary
    print("\n" + "=" * 70)
    print("VERDICT")
    print("=" * 70)
    
    if match_rate >= 95:
        verdict = "‚úÖ EQUIVALENT - Live bot WOULD generate same signals as TPE validate"
    elif match_rate >= 80:
        verdict = "‚ö†Ô∏è MOSTLY EQUIVALENT - Minor differences, likely due to data timing"
    elif match_rate >= 60:
        verdict = "‚ùå PARTIAL MATCH - Significant differences exist"
    else:
        verdict = "‚ùå NOT EQUIVALENT - Major discrepancies between systems"
    
    print(f"\n{verdict}\n")
    
    # Build result
    result = {
        "match_rate": match_rate,
        "tpe_signals": len(tpe_signals),
        "live_signals": len(live_signals),
        "in_both": len(in_both),
        "only_in_tpe": len(only_in_tpe),
        "only_in_live": len(only_in_live),
        "verdict": verdict,
        "discrepancies_tpe_only": [
            {"date": k.date, "symbol": k.symbol, "direction": k.direction}
            for k in list(only_in_tpe)[:50]
        ],
        "discrepancies_live_only": [
            {"date": k.date, "symbol": k.symbol, "direction": k.direction}
            for k in list(only_in_live)[:50]
        ],
    }
    
    # Save results
    output_path = WORKSPACE / "analysis" / "equivalence_test_results.json"
    with open(output_path, 'w') as f:
        json.dump(result, f, indent=2)
    print(f"Results saved to: {output_path}")
    
    return result


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Test equivalence between live bot and TPE validate")
    parser.add_argument("--start", default="2023-01-01", help="Start date (YYYY-MM-DD)")
    parser.add_argument("--end", default="2025-12-31", help="End date (YYYY-MM-DD)")
    parser.add_argument("--verbose", "-v", action="store_true", help="Verbose output")
    
    args = parser.parse_args()
    
    run_equivalence_test(
        start_date=args.start,
        end_date=args.end,
        verbose=args.verbose,
    )
